{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d8aacc",
   "metadata": {},
   "source": [
    "# 03 — XGBoost only (Model + Submission)\n",
    "\n",
    "Este notebook entrena **XGBoost** para *Predict Future Sales* con:\n",
    "- split temporal: **train = meses ≤ 32**, **valid = mes 33**\n",
    "- métrica: **RMSE** (con clipping final a **[0, 20]**)\n",
    "- **early stopping** robusto (compatibilidad entre versiones de `xgboost`)\n",
    "- re-entrenamiento final con **train+valid** usando el mejor número de árboles\n",
    "- generación de **submission** con `ID` correcto (merge con `data/raw/test.csv`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173a7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales\n",
      "RAW_DIR: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales/data/raw exists: True\n",
      "PROC_DIR: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales/data/processed exists: True\n",
      "TEST_RAW: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales/data/raw/test.csv exists: True\n",
      "DATASET_MONTHLY: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales/data/processed/dataset_monthly.csv.gz exists: True\n"
     ]
    }
   ],
   "source": [
    "# Imports + Paths\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "PROJECT_ROOT = Path(\n",
    "    \"/Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales\"\n",
    ")\n",
    "\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROC_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "ARTIFACTS = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_RAW = RAW_DIR / \"test.csv\"\n",
    "DATASET_MONTHLY = PROC_DIR / \"dataset_monthly.csv.gz\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RAW_DIR:\", RAW_DIR, \"exists:\", RAW_DIR.exists())\n",
    "print(\"PROC_DIR:\", PROC_DIR, \"exists:\", PROC_DIR.exists())\n",
    "print(\"TEST_RAW:\", TEST_RAW, \"exists:\", TEST_RAW.exists())\n",
    "print(\"DATASET_MONTHLY:\", DATASET_MONTHLY, \"exists:\", DATASET_MONTHLY.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202bf8ab-b7e9-4375-a876-8d494bb61024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (18129480, 11)\n",
      "date_block_num min/max: 0 34\n",
      "cols (primeras 40): ['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'item_price_mean', 'item_category_id', 'item_cnt_month_lag1', 'item_cnt_month_lag2', 'item_cnt_month_lag3', 'item_cnt_month_lag6', 'item_cnt_month_lag12']\n",
      "train_df: (17915280, 11)\n",
      "test_df : (214200, 10)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos dataset_monthly + checks\n",
    "\n",
    "if not DATASET_MONTHLY.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No existe {DATASET_MONTHLY}. Revisa PROJECT_ROOT y tu estructura de carpetas.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATASET_MONTHLY, compression=\"gzip\")\n",
    "print(\"df shape:\", df.shape)\n",
    "\n",
    "required = {\"shop_id\", \"item_id\", \"date_block_num\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Faltan columnas {missing} en dataset_monthly.\")\n",
    "\n",
    "if \"item_cnt_month\" not in df.columns:\n",
    "    raise ValueError(\n",
    "        \"Falta 'item_cnt_month' en dataset_monthly. Este archivo debe traer el target para meses 0..33.\"\n",
    "    )\n",
    "\n",
    "# tipos\n",
    "for c in [\"shop_id\", \"item_id\", \"date_block_num\"]:\n",
    "    df[c] = df[c].astype(int)\n",
    "\n",
    "print(\"date_block_num min/max:\", int(df[\"date_block_num\"].min()), int(df[\"date_block_num\"].max()))\n",
    "print(\"cols (primeras 40):\", list(df.columns)[:40])\n",
    "\n",
    "# Definir train_df / test_df\n",
    "train_df = df[df[\"date_block_num\"] <= 33].copy()\n",
    "\n",
    "if (df[\"date_block_num\"] == 34).any():\n",
    "    test_df = df[df[\"date_block_num\"] == 34].copy()\n",
    "    test_df = test_df.drop(columns=[\"item_cnt_month\"], errors=\"ignore\")\n",
    "else:\n",
    "    # Si dataset_monthly no trae mes 34, armamos test_df desde test.csv\n",
    "    if not TEST_RAW.exists():\n",
    "        raise FileNotFoundError(f\"No existe {TEST_RAW}.\")\n",
    "    test_raw = pd.read_csv(TEST_RAW)\n",
    "    test_df = test_raw[[\"shop_id\", \"item_id\"]].copy()\n",
    "    test_df[\"date_block_num\"] = 34\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "print(\"test_df :\", test_df.shape)\n",
    "\n",
    "\n",
    "assert train_df[\"date_block_num\"].max() == 33, \"train_df debe llegar a mes 33\"\n",
    "assert set([\"shop_id\", \"item_id\"]).issubset(test_df.columns), \"test_df debe tener shop_id e item_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b9286d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (17388360, 10) X_valid: (526920, 10)\n",
      "n_features: 10\n",
      "Ejemplo features: ['date_block_num', 'shop_id', 'item_id', 'item_price_mean', 'item_category_id', 'item_cnt_month_lag1', 'item_cnt_month_lag2', 'item_cnt_month_lag3', 'item_cnt_month_lag6', 'item_cnt_month_lag12']\n"
     ]
    }
   ],
   "source": [
    "# Realizamos el split temporal (train <=32, valid==33)\n",
    "\n",
    "train_sub = train_df[train_df[\"date_block_num\"] <= 32].copy()\n",
    "valid_df = train_df[train_df[\"date_block_num\"] == 33].copy()\n",
    "\n",
    "y_train = train_sub[\"item_cnt_month\"].astype(float).values\n",
    "y_valid = valid_df[\"item_cnt_month\"].astype(float).values\n",
    "\n",
    "# Features: solo numéricas, excluyendo target\n",
    "drop_cols = {\"item_cnt_month\"}\n",
    "candidate_cols = [c for c in train_sub.columns if c not in drop_cols]\n",
    "feature_cols = [c for c in candidate_cols if pd.api.types.is_numeric_dtype(train_sub[c])]\n",
    "\n",
    "\n",
    "X_train = train_sub[feature_cols]\n",
    "X_valid = valid_df[feature_cols]\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_valid:\", X_valid.shape)\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"Ejemplo features:\", feature_cols[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458986bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK helpers\n"
     ]
    }
   ],
   "source": [
    "# Helpers (RMSE + clip)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "\n",
    "def clip_preds(pred):\n",
    "    # regla de esta competencia\n",
    "    return np.clip(pred, 0, 20)\n",
    "\n",
    "\n",
    "print(\"OK helpers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816ebbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.95444\tvalid-rmse:0.76603\n",
      "[200]\ttrain-rmse:0.54004\tvalid-rmse:0.49211\n",
      "[400]\ttrain-rmse:0.50272\tvalid-rmse:0.48634\n",
      "[600]\ttrain-rmse:0.48418\tvalid-rmse:0.48080\n",
      "[800]\ttrain-rmse:0.47090\tvalid-rmse:0.47959\n",
      "[1000]\ttrain-rmse:0.45995\tvalid-rmse:0.47875\n",
      "[1200]\ttrain-rmse:0.45097\tvalid-rmse:0.47820\n",
      "[1400]\ttrain-rmse:0.44310\tvalid-rmse:0.47780\n",
      "[1480]\ttrain-rmse:0.44031\tvalid-rmse:0.47807\n",
      "VALID RMSE (mes 33): 0.47730566432540356\n",
      "best_iteration: 1280\n"
     ]
    }
   ],
   "source": [
    "# XGBoost via xgb.train (con early stopping)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 10,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 5.0,\n",
    "    \"seed\": 123,\n",
    "    \"tree_method\": \"hist\",\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
    "\n",
    "num_boost_round = 5000\n",
    "early_stopping_rounds = 200\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=200,\n",
    ")\n",
    "\n",
    "pred_valid = clip_preds(booster.predict(dvalid, iteration_range=(0, booster.best_iteration + 1)))\n",
    "valid_rmse = rmse(y_valid, pred_valid)\n",
    "\n",
    "print(\"VALID RMSE (mes 33):\", valid_rmse)\n",
    "print(\"best_iteration:\", booster.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c2c6e4-a4fc-46ef-9e32-7bb89703e55c",
   "metadata": {},
   "source": [
    "**Watchlist.**  \n",
    "La lista `watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]` le indica a XGBoost que reporte el RMSE en ambos conjuntos durante el entrenamiento. Con `verbose_eval=200` imprime el RMSE cada 200 iteraciones.\n",
    "\n",
    "**Early stopping.**  \n",
    "Aunque se permite entrenar hasta `num_boost_round = 5000`, se activa `early_stopping_rounds = 200`, lo que detiene el proceso si el RMSE de validación no mejora durante 200 iteraciones consecutivas. Esto evita sobreajuste y selecciona automáticamente el mejor punto.\n",
    "\n",
    "**Evolución del RMSE.**  \n",
    "En el log, el RMSE de validación cae rápidamente al inicio (por ejemplo, de ~0.766 a ~0.492 en 200 iteraciones) y luego mejora de forma más gradual, estabilizándose alrededor de ~0.478.\n",
    "\n",
    "**Mejor iteración y predicción final.**  \n",
    "- El modelo reporta `best_iteration: 1280`, que es la iteración donde se obtuvo el menor RMSE de validación.\n",
    "- Por eso, al predecir se usa `iteration_range=(0, booster.best_iteration + 1)` para generar predicciones usando únicamente los árboles hasta el punto óptimo (evitando árboles posteriores que no mejoraron validación).\n",
    "\n",
    "**Métrica final.**  \n",
    "El resultado final es `VALID RMSE (mes 33): 0.4773`.  \n",
    "Este RMSE resume el error típico de predicción en la muestra de validación: valores menores indican mejor desempeño.\n",
    "\n",
    "**Conclusión operativa (comparación).**  \n",
    "En esta corrida, XGBoost logra un RMSE de validación (~0.4773), que es mejor (menor) que LightGBM (~0.4945) y CatBoost (~0.5229). Bajo el mismo esquema de validación, XGBoost queda como el modelo con mejor generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "505b9785-d6dd-4626-863f-0cd0bac8e7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained with rounds: 1281\n"
     ]
    }
   ],
   "source": [
    "# FINAL TRAIN (train+valid)\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "best_iter = int(booster.best_iteration)  # 1280\n",
    "\n",
    "# Une train+valid (ya tienes X_train, y_train, X_valid, y_valid)\n",
    "X_trainval = np.vstack([X_train, X_valid])\n",
    "y_trainval = np.concatenate([y_train, y_valid])\n",
    "\n",
    "dtrainval = xgb.DMatrix(X_trainval, label=y_trainval)\n",
    "\n",
    "# Reusamos los mismos params que usasmos arriba (los de xgb.train)\n",
    "\n",
    "booster_final = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrainval,\n",
    "    num_boost_round=best_iter + 1,  # +1 por el iteration_range usado arriba\n",
    "    verbose_eval=200,\n",
    ")\n",
    "\n",
    "print(\"Final model trained with rounds:\", best_iter + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f45021f3-cebb-4132-8393-499a59032455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/andrespadronquintana/Desktop/METODOS_GRAN_ESCALA/TAREAS/tarea1_future_sales/artifacts/submission_xgb.csv\n",
      "   ID  item_cnt_month\n",
      "0   0        0.009959\n",
      "1   1        0.002693\n",
      "2   2        0.043323\n",
      "3   3        0.007192\n",
      "4   4        0.000000\n",
      "len: 214200 ID min/max: 0 214199\n"
     ]
    }
   ],
   "source": [
    "# PREDICT TEST + SUBMISSION\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) Leer test.csv ORIGINAL (el que trae ID)\n",
    "test_raw = pd.read_csv(PROJECT_ROOT / \"data\" / \"raw\" / \"test.csv\")  # columnas: ID, shop_id, item_id\n",
    "\n",
    "\n",
    "# 2) Merge para traer ID y ordenar por ID\n",
    "test_df2 = test_df.merge(\n",
    "    test_raw[[\"ID\", \"shop_id\", \"item_id\"]],\n",
    "    on=[\"shop_id\", \"item_id\"],\n",
    "    how=\"left\",\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "\n",
    "assert test_df2[\"ID\"].notna().all(), \"Hay pares (shop_id,item_id) sin ID: revisa el merge\"\n",
    "test_df2[\"ID\"] = test_df2[\"ID\"].astype(int)\n",
    "test_df2 = test_df2.sort_values(\"ID\").reset_index(drop=True)\n",
    "\n",
    "# 3) Predecimos\n",
    "X_test2 = test_df2[feature_cols]\n",
    "dtest = xgb.DMatrix(X_test2)\n",
    "\n",
    "pred_test = booster_final.predict(dtest)\n",
    "pred_test = np.clip(pred_test, 0, 20)  # estándar de esta comp\n",
    "\n",
    "submission = pd.DataFrame({\"ID\": test_df2[\"ID\"], \"item_cnt_month\": pred_test})\n",
    "\n",
    "sub_path = ARTIFACTS / \"submission_xgb.csv\"\n",
    "submission.to_csv(sub_path, index=False)\n",
    "\n",
    "print(\"Saved:\", sub_path)\n",
    "print(submission.head())\n",
    "print(\"len:\", len(submission), \"ID min/max:\", submission[\"ID\"].min(), submission[\"ID\"].max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
